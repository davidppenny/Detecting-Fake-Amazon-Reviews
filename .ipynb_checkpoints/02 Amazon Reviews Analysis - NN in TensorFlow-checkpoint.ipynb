{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Reviews Analysis - Neural Networks\n",
    "---\n",
    "<b>By David Penny<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing our (very) favorite libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read in the clean data <b>\n",
    "    \n",
    "Let's start off by reading in three versions of the data to use as comparision.\n",
    "    \n",
    "The first is much larger as it has not been downsampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('data/df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>falsified</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text_x</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_scentences_in_text</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>overall_readability_index</th>\n",
       "      <th>total_sentiment</th>\n",
       "      <th>average_review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.086957</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>102.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  falsified  rating  verified_purchase product_category  product_id  \\\n",
       "0       1          1       4                  0               PC  B00008NG7N   \n",
       "\n",
       "                                 product_title review_title  \\\n",
       "0  Targus PAUK10U Ultra Mini USB Keypad, Black       useful   \n",
       "\n",
       "                                       review_text_x  sentiment  ...  \\\n",
       "0  When least you think so, this product will sav...          1  ...   \n",
       "\n",
       "   mean_word_len  num_chars  num_punctuations  num_scentences_in_text  \\\n",
       "0       4.086957        116                 3                       2   \n",
       "\n",
       "   flesch_ease  flesch_kincaid_grade  automated_readability_index  \\\n",
       "0        102.1                   1.9                          3.6   \n",
       "\n",
       "   overall_readability_index  total_sentiment  average_review_sentiment  \n",
       "0                        5.0              6.0                       3.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20809, 24)\n"
     ]
    }
   ],
   "source": [
    "display(df_final.head(1))\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = pd.read_csv('data/df_numerical.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>falsified</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>num_words_in_text</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_words_in_text_no_stop</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_scentences_in_text</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>overall_readability_index</th>\n",
       "      <th>total_sentiment</th>\n",
       "      <th>average_review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>4.086957</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>102.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   falsified  rating  verified_purchase  sentiment  num_words_in_text  \\\n",
       "0          1       4                  0          1                 23   \n",
       "\n",
       "   num_stopwords  num_words_in_text_no_stop  num_unique_words  mean_word_len  \\\n",
       "0             11                         12                21       4.086957   \n",
       "\n",
       "   num_chars  num_punctuations  num_scentences_in_text  flesch_ease  \\\n",
       "0        116                 3                       2        102.1   \n",
       "\n",
       "   flesch_kincaid_grade  automated_readability_index  \\\n",
       "0                   1.9                          3.6   \n",
       "\n",
       "   overall_readability_index  total_sentiment  average_review_sentiment  \n",
       "0                        5.0              6.0                       3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19989, 18)\n"
     ]
    }
   ],
   "source": [
    "display(df_numerical.head(1))\n",
    "print(df_numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled = pd.read_csv('data/df_downsampled.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>falsified</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>overall_readability_index</th>\n",
       "      <th>total_sentiment</th>\n",
       "      <th>average_review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   falsified  verified_purchase  sentiment  num_punctuations  \\\n",
       "0          1                  1          1                 5   \n",
       "\n",
       "   flesch_kincaid_grade  overall_readability_index  total_sentiment  \\\n",
       "0                  10.5                       11.0             16.0   \n",
       "\n",
       "   average_review_sentiment  \n",
       "0                       8.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9104, 8)\n"
     ]
    }
   ],
   "source": [
    "display(df_downsampled.head(1))\n",
    "print(df_downsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['falsified', 'verified_purchase', 'sentiment', 'num_punctuations',\n",
       "       'flesch_kincaid_grade', 'overall_readability_index', 'total_sentiment',\n",
       "       'average_review_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we choose which version of the df we will use\n",
    "#dataframe = df_final\n",
    "#dataframe = df_numerical\n",
    "dataframe = df_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Dummy Classifier <b>\n",
    "\n",
    "Let's get a baseline to see how a dummy classifier would score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [1]\n",
      "Test score:  0.4995606326889279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate input features and target\n",
    "y = dataframe['falsified']\n",
    "X = dataframe.drop(columns='falsified', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels: ', (np.unique(dummy_pred)))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test score: ', accuracy_score(y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by testing a very basic NN model to get another baseline for our accuracy potential.\n",
    "\n",
    "/// CAUTION /// This takes a long time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9104,)\n",
      "(9104, 7)\n",
      "The test accuracy is: 0.482\n"
     ]
    }
   ],
   "source": [
    "y = dataframe['falsified']\n",
    "X = dataframe.drop(columns='falsified')\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "NN_model = MLPClassifier(hidden_layer_sizes=(17,128,128,128,128,2), solver='lbfgs', max_iter=10000)\n",
    "NN_model.fit(X,y);\n",
    "\n",
    "print(f'The test accuracy is: {NN_model.score(X,y):0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5826 train examples\n",
      "1457 validation examples\n",
      "1821 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('falsified')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our data sets\n",
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['verified_purchase', 'sentiment', 'num_punctuations', 'flesch_kincaid_grade', 'overall_readability_index', 'total_sentiment', 'average_review_sentiment']\n",
      "A batch of ages: tf.Tensor([ 9.  4. 16.  9. 13.], shape=(5,), dtype=float64)\n",
      "A batch of targets: tf.Tensor([1 1 0 1 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Describing our data sets\n",
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['total_sentiment'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('falsified')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['verified_purchase', 'sentiment', 'num_punctuations', 'flesch_kincaid_grade', 'overall_readability_index', 'total_sentiment', 'average_review_sentiment']\n",
      "A batch of ages: tf.Tensor([14. 15. 12. 10. 22.], shape=(5,), dtype=float64)\n",
      "A batch of targets: tf.Tensor([1 1 0 1 1], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['total_sentiment'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this batch to demonstrate several types of feature columns\n",
    "example_batch = next(iter(train_ds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# DOWNSAMPLED numeric cols\n",
    "for header in ['verified_purchase', 'sentiment', 'num_punctuations',\n",
    "       'flesch_kincaid_grade', 'overall_readability_index', 'total_sentiment',\n",
    "       'average_review_sentiment']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Here's where the magic happens: <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.7059 - accuracy: 0.4856 - val_loss: 0.6942 - val_accuracy: 0.5024\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.4818 - val_loss: 0.6958 - val_accuracy: 0.5024\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4818 - val_loss: 0.6883 - val_accuracy: 0.5024\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.4940 - val_loss: 0.6505 - val_accuracy: 0.5051\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6274 - val_loss: 0.5954 - val_accuracy: 0.7076\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7096 - val_loss: 0.5277 - val_accuracy: 0.7632\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7703 - val_loss: 0.4837 - val_accuracy: 0.7852\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7949 - val_loss: 0.4993 - val_accuracy: 0.7742\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7973 - val_loss: 0.4717 - val_accuracy: 0.7962\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8031 - val_loss: 0.4791 - val_accuracy: 0.7968\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8067 - val_loss: 0.4692 - val_accuracy: 0.7982\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8088 - val_loss: 0.4727 - val_accuracy: 0.8099\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8115 - val_loss: 0.4683 - val_accuracy: 0.7996\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8079 - val_loss: 0.4641 - val_accuracy: 0.8071\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8096 - val_loss: 0.4747 - val_accuracy: 0.8106\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8119 - val_loss: 0.4628 - val_accuracy: 0.8078\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8105 - val_loss: 0.4675 - val_accuracy: 0.8113\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8129 - val_loss: 0.4672 - val_accuracy: 0.8113\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8134 - val_loss: 0.4617 - val_accuracy: 0.8099\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8136 - val_loss: 0.4592 - val_accuracy: 0.8078\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8124 - val_loss: 0.4683 - val_accuracy: 0.8119\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8138 - val_loss: 0.4610 - val_accuracy: 0.8051\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8143 - val_loss: 0.4579 - val_accuracy: 0.8099\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8145 - val_loss: 0.4610 - val_accuracy: 0.8133\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8143 - val_loss: 0.4705 - val_accuracy: 0.8119\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8141 - val_loss: 0.4666 - val_accuracy: 0.8140\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8143 - val_loss: 0.4662 - val_accuracy: 0.8126\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8145 - val_loss: 0.4576 - val_accuracy: 0.8140\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.8134 - val_loss: 0.4607 - val_accuracy: 0.8126\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8158 - val_loss: 0.4746 - val_accuracy: 0.8133\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8146 - val_loss: 0.4563 - val_accuracy: 0.8085\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8139 - val_loss: 0.4624 - val_accuracy: 0.8133\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8153 - val_loss: 0.4565 - val_accuracy: 0.8099\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.8145 - val_loss: 0.4551 - val_accuracy: 0.8085\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8150 - val_loss: 0.4586 - val_accuracy: 0.8140\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8155 - val_loss: 0.4559 - val_accuracy: 0.8147\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8153 - val_loss: 0.4568 - val_accuracy: 0.8154\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8127 - val_loss: 0.4683 - val_accuracy: 0.8126\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8162 - val_loss: 0.4535 - val_accuracy: 0.8113\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8175 - val_loss: 0.4550 - val_accuracy: 0.8085\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8143 - val_loss: 0.4536 - val_accuracy: 0.8133\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8157 - val_loss: 0.4707 - val_accuracy: 0.8126\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8177 - val_loss: 0.4553 - val_accuracy: 0.8154\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8181 - val_loss: 0.4530 - val_accuracy: 0.8140\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8162 - val_loss: 0.4623 - val_accuracy: 0.8161\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8172 - val_loss: 0.4553 - val_accuracy: 0.8147\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8181 - val_loss: 0.4570 - val_accuracy: 0.8051\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8163 - val_loss: 0.4527 - val_accuracy: 0.8119\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8169 - val_loss: 0.4572 - val_accuracy: 0.8147\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8170 - val_loss: 0.4542 - val_accuracy: 0.8106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14da080b8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(4, activation='sigmoid'),\n",
    "  layers.Dense(128, activation='sigmoid'),\n",
    "  layers.Dense(128, activation='sigmoid'),\n",
    "  layers.Dense(128, activation='sigmoid'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          callbacks=[tensorboard_callback],\n",
    "          epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8215\n",
      "Accuracy 0.8215266466140747\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Summary <b>\n",
    "    \n",
    "It's not bad! But I was hoping that we would score much higher than 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/bin/tensorboard\", line 8, in <module>\n",
       "    sys.exit(run_main())\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorboard/main.py\", line 65, in run_main\n",
       "    default.get_plugins() + default.get_dynamic_plugins(),\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorboard/default.py\", line 125, in get_dynamic_plugins\n",
       "    \"tensorboard_plugins\"\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorboard/default.py\", line 124, in <listcomp>\n",
       "    for entry_point in pkg_resources.iter_entry_points(\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2460, in load\n",
       "    self.require(*args, **kwargs)\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2483, in require\n",
       "    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n",
       "  File \"/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
       "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
       "pkg_resources.VersionConflict: (grpcio 1.23.0 (/Users/davepenny/opt/anaconda3/envs/deeplearning/lib/python3.6/site-packages), Requirement.parse('grpcio>=1.24.3'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
